{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-05T09:15:34.860926Z",
     "iopub.status.busy": "2026-01-05T09:15:34.860596Z",
     "iopub.status.idle": "2026-01-05T16:47:30.388138Z",
     "shell.execute_reply": "2026-01-05T16:47:30.387040Z",
     "shell.execute_reply.started": "2026-01-05T09:15:34.860884Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 20 epochs (cosine LR, no warmup)\n",
      "Base LR: 0.0001, Min LR: 1e-07\n",
      "L2 Regularization (weight_decay): 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 345\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mL2 Regularization (weight_decay): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mWEIGHT_DECAY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, NUM_EPOCHS + \u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m     train_loss, train_mse = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m     val_loss, val_mse = eval_epoch(model, val_loader, criterion)\n\u001b[32m    349\u001b[39m     current_lr = optimizer.param_groups[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 224\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, loader, optimizer, criterion)\u001b[39m\n\u001b[32m    222\u001b[39m optimizer.zero_grad()\n\u001b[32m    223\u001b[39m logits = model(imgs)\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m loss.backward()\n\u001b[32m    226\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleks\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1778\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1777\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleks\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1789\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1784\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1785\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1786\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1787\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1788\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1789\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1792\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 182\u001b[39m, in \u001b[36mCombinedLoss.forward\u001b[39m\u001b[34m(self, logits, targets)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, logits, targets):\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     dice = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdice_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m     bce = \u001b[38;5;28mself\u001b[39m.bce_loss(logits, targets)\n\u001b[32m    185\u001b[39m     combined = \u001b[38;5;28mself\u001b[39m.dice_weight * dice + \u001b[38;5;28mself\u001b[39m.bce_weight * bce\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleks\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1778\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1777\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleks\\anaconda3\\envs\\pytorch311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1789\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1784\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1785\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1786\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1787\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1788\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1789\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1792\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 164\u001b[39m, in \u001b[36mDiceLoss.forward\u001b[39m\u001b[34m(self, logits, targets)\u001b[39m\n\u001b[32m    161\u001b[39m targets_flat = targets.view(-\u001b[32m1\u001b[39m)\n\u001b[32m    163\u001b[39m intersection = (probs_flat * targets_flat).sum()\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m union = \u001b[43mprobs_flat\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m + targets_flat.sum()\n\u001b[32m    166\u001b[39m dice = \u001b[32m1\u001b[39m - (\u001b[32m2\u001b[39m * intersection + \u001b[38;5;28mself\u001b[39m.smooth) / (union + \u001b[38;5;28mself\u001b[39m.smooth)\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dice\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import io\n",
    "import base64\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "\n",
    "DATA_ROOT = Path(\"D:/DIS5K/DIS-TR\")\n",
    "TEST_ROOT = Path(\"D:/orig_1024\")\n",
    "MODEL_DIR = Path(\"D:/model\")\n",
    "\n",
    "\n",
    "# ==================== SEED / DEVICE ====================\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "#torch.manual_seed(SEED)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# ==================== PATHS / CONFIG ====================\n",
    "\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "IMG_SIZE = (1024, 1024)\n",
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "\n",
    "LR = 1e-4\n",
    "ETA_MIN = 1e-7\n",
    "WEIGHT_DECAY = 1e-4\n",
    "RUN_TRAINING = True\n",
    "\n",
    "\n",
    "\n",
    "# ==================== DATASET ====================\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_root,\n",
    "        size=(1024, 1024),\n",
    "        mask_subfolder=\"gt\",\n",
    "        image_subfolder=\"im\",\n",
    "        image_format=\".jpg\",\n",
    "        mask_format=\".png\",\n",
    "        num_mask_channels=1,\n",
    "    ):\n",
    "        self.size = size\n",
    "        self.data_root = Path(data_root)\n",
    "        if not self.data_root.exists():\n",
    "            raise ValueError(\"Instance images root doesn't exists.\")\n",
    "\n",
    "\n",
    "        self.mask_subfolder = mask_subfolder\n",
    "        self.image_subfolder = image_subfolder\n",
    "        self.image_format = image_format\n",
    "        self.mask_format = mask_format\n",
    "        self.num_mask_channels = num_mask_channels\n",
    "\n",
    "\n",
    "        self.data = [\n",
    "            i.rsplit(\".\", 1)[0]\n",
    "            for i in os.listdir(str(self.data_root / self.mask_subfolder))\n",
    "            if i.endswith(self.mask_format)\n",
    "        ]\n",
    "        self._length = len(self.data)\n",
    "\n",
    "\n",
    "        self.image_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5], [0.5]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "        self.mask_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        obj = self.data[index]\n",
    "\n",
    "\n",
    "        mask = Image.open(self.data_root / self.mask_subfolder / f\"{obj}{self.mask_format}\")\n",
    "        if self.num_mask_channels == 3:\n",
    "            mask = mask.convert(\"RGB\")\n",
    "\n",
    "\n",
    "        img = Image.open(self.data_root / self.image_subfolder / f\"{obj}{self.image_format}\").convert(\"RGB\")\n",
    "\n",
    "\n",
    "        mask = self.mask_transforms(mask)\n",
    "        img = self.image_transforms(img)\n",
    "\n",
    "\n",
    "        return {\"mask\": mask, \"img\": img}\n",
    "\n",
    "\n",
    "\n",
    "def get_dataloaders(train_root: Path, size=(1024, 1024), batch_size=32):\n",
    "    train_dataset = SegmentationDataset(\n",
    "        data_root=train_root,\n",
    "        size=size,\n",
    "        mask_subfolder=\"gt\",\n",
    "        image_subfolder=\"im\",\n",
    "        image_format=\".jpg\",\n",
    "        mask_format=\".png\",\n",
    "        num_mask_channels=1,\n",
    "    )\n",
    "    val_size = max(1, int(0.1 * len(train_dataset)))\n",
    "    train_size = len(train_dataset) - val_size\n",
    "    train_ds, val_ds = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice Loss Ð´Ð»Ñ Ð±Ð¸Ð½Ð°Ñ€Ð½Ð¾Ð¹ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸\"\"\"\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        probs_flat = probs.view(-1)\n",
    "        targets_flat = targets.view(-1)\n",
    "\n",
    "        intersection = (probs_flat * targets_flat).sum()\n",
    "        union = probs_flat.sum() + targets_flat.sum()\n",
    "\n",
    "        dice = 1 - (2 * intersection + self.smooth) / (union + self.smooth)\n",
    "        return dice\n",
    "\n",
    "\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ loss: Dice + BCE\"\"\"\n",
    "    def __init__(self, dice_weight=0.7, bce_weight=0.3, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.dice_weight = dice_weight\n",
    "        self.bce_weight = bce_weight\n",
    "\n",
    "        self.dice_loss = DiceLoss(smooth=smooth)\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        dice = self.dice_loss(logits, targets)\n",
    "        bce = self.bce_loss(logits, targets)\n",
    "\n",
    "        combined = self.dice_weight * dice + self.bce_weight * bce\n",
    "        return combined\n",
    "\n",
    "\n",
    "# ==================== MODEL ====================\n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"efficientnet-b2\",        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                 \n",
    "    classes=1,                     \n",
    "    activation=None,                \n",
    ")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model = model.to(device)\n",
    "# ==================== METRICS ====================\n",
    "def mse_metric(logits, target):\n",
    "    probs = torch.sigmoid(logits)\n",
    "    return F.mse_loss(probs, target)\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_mse = 0.0\n",
    "\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"train\", leave=False):\n",
    "        imgs = batch[\"img\"].to(device)\n",
    "        masks = batch[\"mask\"].to(device)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        total_mse += mse_metric(logits, masks).item() * imgs.size(0)\n",
    "\n",
    "\n",
    "    n = len(loader.dataset)\n",
    "    return total_loss / n, total_mse / n\n",
    "\n",
    "\n",
    "\n",
    "def eval_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_mse = 0.0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"val\", leave=False):\n",
    "            imgs = batch[\"img\"].to(device)\n",
    "            masks = batch[\"mask\"].to(device)\n",
    "\n",
    "\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, masks)\n",
    "\n",
    "\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            total_mse += mse_metric(logits, masks).item() * imgs.size(0)\n",
    "\n",
    "\n",
    "    n = len(loader.dataset)\n",
    "    return total_loss / n, total_mse / n\n",
    "\n",
    "\n",
    "\n",
    "# ==================== PLOTS  ====================\n",
    "def plot_metrics(train_losses, val_losses, train_mses, val_mses, learning_rates, save_dir):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "\n",
    "    #loss\n",
    "    axes[0, 0].plot(train_losses, label=\"Train Loss\", linewidth=2, marker=\"o\")\n",
    "    axes[0, 0].plot(val_losses, label=\"Val Loss\", linewidth=2, marker=\"s\")\n",
    "    axes[0, 0].set_xlabel(\"Epoch\")\n",
    "    axes[0, 0].set_ylabel(\"Loss\")\n",
    "    axes[0, 0].set_title(\"Training Loss\")\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "    #MSE\n",
    "    axes[0, 1].plot(train_mses, label=\"Train MSE\", linewidth=2, marker=\"o\")\n",
    "    axes[0, 1].plot(val_mses, label=\"Val MSE\", linewidth=2, marker=\"s\")\n",
    "    axes[0, 1].set_xlabel(\"Epoch\")\n",
    "    axes[0, 1].set_ylabel(\"MSE\")\n",
    "    axes[0, 1].set_title(\"MSE Metric\")\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "    # LR\n",
    "    axes[1, 0].plot(learning_rates, linewidth=2, color=\"green\", marker=\"o\")\n",
    "    axes[1, 0].set_xlabel(\"Epoch\")\n",
    "    axes[1, 0].set_ylabel(\"Learning Rate\")\n",
    "    axes[1, 0].set_title(\"Learning Rate Schedule (Cosine)\")\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].set_yscale(\"log\")\n",
    "\n",
    "\n",
    "    #val loss \n",
    "    axes[1, 1].plot(val_losses, linewidth=2.5, color=\"red\", marker=\"o\")\n",
    "    axes[1, 1].set_xlabel(\"Epoch\")\n",
    "    axes[1, 1].set_ylabel(\"Val Loss\")\n",
    "    axes[1, 1].set_title(\"Validation Loss (Detail)\")\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / \"training_plots.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ==================== TRAIN ====================\n",
    "\n",
    "\n",
    "train_loader, val_loader = get_dataloaders(DATA_ROOT, size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "criterion = CombinedLoss(dice_weight=0.5, bce_weight=0.5, smooth=1.0)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    ")\n",
    "\n",
    "\n",
    "best_val_mse = float(\"inf\")\n",
    "best_path = MODEL_DIR / \"unet_dis_best.pth\"\n",
    "\n",
    "\n",
    "train_losses, val_losses, train_mses, val_mses, learning_rates = [], [], [], [], []\n",
    "\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    print(f\"Training {NUM_EPOCHS} epochs (cosine LR, no warmup)\")\n",
    "    print(f\"Base LR: {LR}, Min LR: {ETA_MIN}\")\n",
    "    print(f\"L2 Regularization (weight_decay): {WEIGHT_DECAY}\\n\")\n",
    "\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        train_loss, train_mse = train_epoch(model, train_loader, optimizer, criterion)\n",
    "        val_loss, val_mse = eval_epoch(model, val_loader, criterion)\n",
    "\n",
    "\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_mses.append(train_mse)\n",
    "        val_mses.append(val_mse)\n",
    "        learning_rates.append(current_lr)\n",
    "\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:2d}/{NUM_EPOCHS}: \"\n",
    "            f\"train_loss={train_loss:.6f} val_loss={val_loss:.6f} val_mse={val_mse:.6f} LR={current_lr:.8f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "        if val_mse < best_val_mse:\n",
    "            best_val_mse = val_mse\n",
    "            torch.save({\"model_state\": model.state_dict()}, best_path)\n",
    "            print(\"  âœ… Saved best model\")\n",
    "\n",
    "\n",
    "        plot_metrics(train_losses, val_losses, train_mses, val_mses, learning_rates, MODEL_DIR)\n",
    "\n",
    "\n",
    "        old_lr = current_lr\n",
    "        scheduler.step(val_mse)  \n",
    "        new_lr = optimizer.param_groups[0][\"lr\"]\n",
    " \n",
    "        if new_lr != old_lr:\n",
    "            print(f\"  ðŸ“‰ LR reduced: {old_lr:.8f} â†’ {new_lr:.8f}\")\n",
    "\n",
    "\n",
    "    print(f\"\\nâœ… Training completed! Best val_mse: {best_val_mse:.6f}\\n\")\n",
    "\n",
    "\n",
    "else:\n",
    "    if best_path.exists():\n",
    "        model.load_state_dict(torch.load(best_path)[\"model_state\"])\n",
    "\n",
    "\n",
    "# ==================== POSTPROCESSING ====================\n",
    "def postprocess_alpha_mask(mask_prob):\n",
    "    \"\"\"ÐŸÐ¾ÑÑ‚Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð°Ð»ÑŒÑ„Ð°-Ð¼Ð°ÑÐºÐ¸: Ð¼Ð¾Ñ€Ñ„Ð¾Ð»Ð¾Ð³Ð¸Ñ + ÑÐ³Ð»Ð°Ð¶Ð¸Ð²Ð°Ð½Ð¸Ðµ\"\"\"\n",
    "    mask = (mask_prob * 255).astype(np.uint8)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    mask = cv2.GaussianBlur(mask, (3, 3), 1.0)\n",
    "    return mask\n",
    "\n",
    "\n",
    "# ==================== INFERENCE ====================\n",
    "model.eval()\n",
    "\n",
    "test_dataset = TestImageDataset(TEST_ROOT, size=(1024, 1024))\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "rows = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"test\", leave=False):\n",
    "        imgs = batch[\"img\"].to(device)\n",
    "        names = batch[\"path\"]\n",
    "        logits = model(imgs)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        \n",
    "        mask_prob = probs[0, 0].cpu().numpy()\n",
    "        mask = postprocess_alpha_mask(mask_prob) \\\n",
    "        \n",
    "        pil_mask = Image.fromarray(mask, mode=\"L\")\n",
    "        buf = io.BytesIO()\n",
    "        pil_mask.save(buf, format=\"PNG\")\n",
    "        buf.seek(0)\n",
    "        image_utf = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
    "        rows.append({\"filename\": names[0].split(\".\")[0], \"image_utf\": image_utf})\n",
    "\n",
    "\n",
    "submission = pd.DataFrame(rows)\n",
    "submission_path = MODEL_DIR / \"submission.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Saved submission to {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T20:16:04.328691Z",
     "iopub.status.busy": "2026-01-04T20:16:04.328083Z",
     "iopub.status.idle": "2026-01-04T20:16:04.575365Z",
     "shell.execute_reply": "2026-01-04T20:16:04.574631Z",
     "shell.execute_reply.started": "2026-01-04T20:16:04.328660Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan  9 14:01:45 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 591.74                 Driver Version: 591.74         CUDA Version: 13.1     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 5060 Ti   WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   49C    P5             18W /  180W |    1571MiB /  16311MiB |      1%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1820    C+G   ...ntrolPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A            4184    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A            6348    C+G   ...rzrea0\\XboxGameBarSpotify.exe      N/A      |\n",
      "|    0   N/A  N/A            6980    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            7292    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            7368    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A            7472    C+G   ...Telegram Desktop\\Telegram.exe      N/A      |\n",
      "|    0   N/A  N/A            7544    C+G   ...2txyewy\\CrossDeviceResume.exe      N/A      |\n",
      "|    0   N/A  N/A            8728    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A            8740    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           10816    C+G   ....0.3650.96\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           13024    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           14464    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           15356    C+G   ...em32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A           17252    C+G   ....0.3650.96\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           17372    C+G   ...ms\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A           18220    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           18844    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           18952    C+G   ....0.3650.96\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           19996    C+G   ...owser\\Application\\browser.exe      N/A      |\n",
      "|    0   N/A  N/A           21944    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           22144    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T16:47:53.940866Z",
     "iopub.status.busy": "2026-01-05T16:47:53.940532Z",
     "iopub.status.idle": "2026-01-05T16:47:53.948182Z",
     "shell.execute_reply": "2026-01-05T16:47:53.947628Z",
     "shell.execute_reply.started": "2026-01-05T16:47:53.940833Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "import pandas as pd\n",
    "\n",
    "class TestImageDataset(Dataset):\n",
    "    def __init__(self, test_root, size=(1024, 1024)):\n",
    "        self.size = size\n",
    "        self.test_root = Path(test_root)\n",
    "\n",
    "        if not self.test_root.exists():\n",
    "            raise ValueError(\"Test images root doesn't exist\")\n",
    "\n",
    "        # Ð˜Ñ‰ÐµÐ¼ Ð²ÑÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð² Ð¿Ð°Ð¿ÐºÐµ\n",
    "        self.image_files = sorted([\n",
    "            f for f in os.listdir(str(self.test_root))\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ])\n",
    "\n",
    "        self.image_transforms = transforms.Compose([\n",
    "            transforms.Resize(size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5]),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.image_files[index]\n",
    "        img_path = self.test_root / filename\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = self.image_transforms(img)\n",
    "\n",
    "        return {\"img\": img, \"path\": filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T16:47:55.756413Z",
     "iopub.status.busy": "2026-01-05T16:47:55.756081Z",
     "iopub.status.idle": "2026-01-05T16:48:19.390730Z",
     "shell.execute_reply": "2026-01-05T16:48:19.389897Z",
     "shell.execute_reply.started": "2026-01-05T16:47:55.756385Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/4254302542.py:17: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  pil_mask = Image.fromarray(mask, mode=\"L\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "Saved submission to /kaggle/working/submission.csv\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "\n",
    "test_dataset = TestImageDataset(TEST_ROOT, size=(1024, 1024))\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "rows = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"test\", leave=False):\n",
    "        imgs = batch[\"img\"].to(device)\n",
    "        names = batch[\"path\"]\n",
    "        logits = model(imgs)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        mask = (probs[0, 0].cpu().numpy() * 255.0).astype(np.uint8)\n",
    "        print(mask.shape)\n",
    "        pil_mask = Image.fromarray(mask, mode=\"L\")\n",
    "        buf = io.BytesIO()\n",
    "        pil_mask.save(buf, format=\"PNG\")\n",
    "        image_utf = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
    "        rows.append({\"filename\": names[0].split(\".\")[0], \"image_utf\": image_utf})\n",
    "\n",
    "\n",
    "submission = pd.DataFrame(rows)\n",
    "submission_path = MODEL_DIR / \"submission.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Saved submission to {submission_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9150524,
     "sourceId": 14332600,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9159000,
     "sourceId": 14344377,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9159041,
     "sourceId": 14344431,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9190100,
     "sourceId": 14389928,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pytorch311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
